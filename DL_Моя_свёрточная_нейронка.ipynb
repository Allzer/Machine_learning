{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allzer/Machine_learning/blob/main/DL_%D0%9C%D0%BE%D1%8F_%D1%81%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BA%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55oSp9l0Fp9w"
      },
      "source": [
        "Задача. Создать нейронную сеть, которая будет классифицировать изображения с точностью больше 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ON3EJa9-C91l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from tqdm import tqdm\n",
        "import scipy.io as sio\n",
        "import os\n",
        "from numpy.random.mtrand import shuffle\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg5BbBLyJ92L",
        "outputId": "00da56ec-3bd1-4916-b8b6-1a93a7f68a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: drive/MyDrive/data/extra_32x32.mat\n",
            "Using downloaded and verified file: drive/MyDrive/data/train_32x32.mat\n",
            "Using downloaded and verified file: drive/MyDrive/data/test_32x32.mat\n"
          ]
        }
      ],
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor()]) #позволяет делать преобразования с нашей выборкой (преобразуем картинку в тензор) , transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "trainset = torchvision.datasets.SVHN(root='drive/MyDrive/data', split='extra', transform=transforms, target_transform=None, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 4,shuffle = True, num_workers=2)\n",
        "\n",
        "valset = torchvision.datasets.SVHN(root='drive/MyDrive/data',split='train', transform=transforms, target_transform=None, download=True)\n",
        "valloader = torch.utils.data.DataLoader(trainset,batch_size = 4,shuffle = None, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.SVHN(root='drive/MyDrive/data', split='test', transform=transforms, target_transform=None, download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 4,shuffle = False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "d2V0auUpQ9__"
      },
      "outputs": [],
      "source": [
        "classes = tuple(str(i) for i in range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "axzB0DjOSBDm"
      },
      "outputs": [],
      "source": [
        "class simpleNS(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(simpleNS, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=20, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(4*25*5,500)\n",
        "    self.fc2 = nn.Linear(500, 250)\n",
        "    self.fc3 = nn.Linear(250,50)\n",
        "    self.fc4 = nn.Linear(50,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1,4*25*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASGQ8LihUL46"
      },
      "outputs": [],
      "source": [
        "net = simpleNS()\n",
        "batch = next(iter(trainloader))\n",
        "net.forward(torch.FloatTensor(batch[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IQMVkGUbFiG"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "LR = 1e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=LR)\n",
        "losses = []\n",
        "\n",
        "for epoch in tqdm_notebook(range(3)):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i,batch in enumerate(tqdm_notebook(trainloader)):\n",
        "    x_batch, y_batch = batch\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = net(x_batch)\n",
        "    loss = loss_fn(y_pred,y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if i%2000 == 1999:\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch+1, i+1, running_loss/2000))\n",
        "      losses.append(running_loss)\n",
        "      running_loss = 0.0\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(np.arange(len(losses)),losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK0YbnY-iZ2U",
        "outputId": "726fbad8-3725-4716-9bc9-a5378789468a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of     0 : 93 %\n",
            "Accuracy of     1 : 94 %\n",
            "Accuracy of     2 : 94 %\n",
            "Accuracy of     3 : 92 %\n",
            "Accuracy of     4 : 95 %\n",
            "Accuracy of     5 : 84 %\n",
            "Accuracy of     6 : 92 %\n",
            "Accuracy of     7 : 93 %\n",
            "Accuracy of     8 : 88 %\n",
            "Accuracy of     9 : 90 %\n"
          ]
        }
      ],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    y_pred = net(images)\n",
        "    _, predicted = torch.max(y_pred,1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] +=1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' %(classes[i], 100*class_correct[i]/class_total[i]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vnCJpS86c1vvEwEZ4paF6WwHdmyx1X2f",
      "authorship_tag": "ABX9TyMFIgjcbbkDeITZBdyEpLFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}