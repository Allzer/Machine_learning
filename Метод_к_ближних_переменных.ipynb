{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allzer/Machine_learning/blob/main/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BA_%D0%B1%D0%BB%D0%B8%D0%B6%D0%BD%D0%B8%D1%85_%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У меня не получилось делать так, как в примере, я буду делать по своему, а потом сравню результаты\n"
      ],
      "metadata": {
        "id": "1uKFfXFe6MXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11o6Wx-vYeas"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.io as sio\n",
        "from sklearn.model_selection import train_test_split #разбивает данные для тестирования и тренировки\n",
        "\n",
        "#библиотеки курса\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#загружаем тестовые данные\n",
        "def load_data_mat(filename, max_samples, seed=64):\n",
        "    raw = sio.loadmat(filename) #загружаем файл\n",
        "    x = raw['X'] #Передаём массивы принадлежащие Х\n",
        "    y = raw['y'] #Передаём массивы принадлежащие у\n",
        "\n",
        "    x = np.moveaxis(x, [3], [0]) #Перемещение оси массива. 3 ось мы ставим на нулевую\n",
        "    y = y.flatten() #Возвращает одномерный массив (для уменьшения массива до одного измерения)\n",
        "\n",
        "    y[y == 10] = 0 #все значения 10 присваивается знаение 0\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    samples = np.random.choice(np.arange(x.shape[0]), max_samples, replace=False) #x.shape[0] передаёт в данном случае\n",
        "    #рандомную строку 2D массива\n",
        "    #np.choice - вернет max_sample случайных чисeл от 0 до x.shape[0].\n",
        "    return x[samples].astype(np.float32), y[samples] #возвращаем массив иксов и игриков с одинаковыми семплами\n",
        "\n",
        "def load_svhn(folder, max_train, max_test):\n",
        "\n",
        "    #train_x - массив (num_train,32,32,3) - тренировочные изображения\n",
        "    #train_y - массив (num_train) - training labels - тренировочный разделитель\n",
        "    #test_X, np array (num_test, 32, 32, 3) - тестовые изображения\n",
        "    #test_y, np array of int (num_test) - тестовый разделитель\n",
        "\n",
        "    train_X, train_y = load_data_mat(os.path.join(folder, \"train_32x32.mat\"), max_train) #Загружает данные для тренировки\n",
        "    test_X, test_y = load_data_mat(os.path.join(folder, \"test_32x32.mat\"), max_test) #Загружает данные для тестов\n",
        "    return train_X, train_y, test_X, test_y #Возвращает загруенные данные\n",
        "\n",
        "def random_split_train_val(X, y, num_val, seed=35):\n",
        "    '''\n",
        "    Randomly splits dataset into training and validation\n",
        "\n",
        "    Arguments:\n",
        "    X - np-массив с выборками\n",
        "    y - np-массив с метками\n",
        "    num_val - количество образцов для проверки\n",
        "    seed - random seed\n",
        "\n",
        "    Returns:\n",
        "    train_X, np array (num_train, 32, 32, 3) - обучающие изображения\n",
        "    train_y, np array of int (num_train) - обучающие метки\n",
        "    val_X, np array (num_val, 32, 32, 3) - validation images\n",
        "    val_y, np array of int (num_val) - validation labels\n",
        "    '''\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    indices = np.arange(X.shape[0]) #передаёт в переменную одномерны массив\n",
        "    np.random.shuffle(indices) #измените последовательность на месте, перетасовав ее содержимое.\n",
        "\n",
        "    train_indices = indices[:-num_val] #получаем все элементы массива кроме элемента с индексом -num_val\n",
        "    train_X = X[train_indices]\n",
        "    train_y = y[train_indices]\n",
        "\n",
        "    val_indices = indices[-num_val:]\n",
        "    val_X = X[val_indices]\n",
        "    val_y = y[val_indices]\n",
        "\n",
        "    return train_X, train_y, val_X, val_y\n",
        "\n",
        "train_x, train_y, test_x, test_y = load_svhn(\"drive/MyDrive/data\", max_train=1000, max_test=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем класс KNN"
      ],
      "metadata": {
        "id": "cGznIon-8CTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import parse_qs\n",
        "class KNN:\n",
        "    \"\"\"\n",
        "    K-neariest-neighbor classifier using L1 loss\n",
        "    \"\"\"\n",
        "    def __init__(self, k=1):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.train_X = X\n",
        "        self.train_y = y\n",
        "\n",
        "    def predict(self, X, num_loops=1):\n",
        "        '''\n",
        "        Uses the KNN model to predict clases for the data samples provided\n",
        "\n",
        "        Arguments:\n",
        "        X, np array (num_samples, num_features) - samples to run\n",
        "           through the model\n",
        "        num_loops, int - which implementation to use\n",
        "\n",
        "        Returns:\n",
        "        predictions, np array of ints (num_samples) - predicted class\n",
        "           for each sample\n",
        "        '''\n",
        "        if num_loops == 0:\n",
        "            dists = self.compute_distances_no_loops(X)\n",
        "        elif num_loops == 1:\n",
        "            dists = self.compute_distances_one_loop(X)\n",
        "        else:\n",
        "            dists = self.compute_distances_two_loops(X)\n",
        "\n",
        "        if self.train_y.dtype == np.bool:\n",
        "            return self.predict_labels_binary(dists)\n",
        "        else:\n",
        "            return self.predict_labels_multiclass(dists)\n",
        "\n",
        "\n",
        "    def compute_distances_two_loops(self, X):\n",
        "      num_train = self.train_X.shape[0]\n",
        "      num_test = X.shape[0]\n",
        "      dists = np.zeros((num_test, num_train),np.float32)\n",
        "\n",
        "      for i_test in range(num_test):\n",
        "        for i_train in range(num_train):\n",
        "          dists[i_test][i_train] = np.sum(np.abs((X[i_test] - self.train_X[i_train])))\n",
        "          pass\n",
        "      return  dists\n",
        "    #(X[i_test] - self.train_X[i_train]) - вектор рсстояния(см в тетради)\n",
        "    #X - переданный тестовый набор\n",
        "    #self.train_X - хранятся проверочные картинки\n",
        "\n",
        "    def compute_distances_one_loop(self, X):\n",
        "        '''\n",
        "        Computes L1 distance from every sample of X to every training sample\n",
        "        Vectorizes some of the calculations, so only 1 loop is used\n",
        "\n",
        "        Arguments:\n",
        "        X, np array (num_test_samples, num_features) - samples to run\n",
        "\n",
        "        Returns:\n",
        "        dists, np array (num_test_samples, num_train_samples) - array\n",
        "           with distances between each test and each train sample\n",
        "        '''\n",
        "        num_train = self.train_X.shape[0]\n",
        "        num_test = X.shape[0]\n",
        "        dists = np.zeros((num_test, num_train), np.float32)\n",
        "        for i_test in range(num_test):\n",
        "            dists[i_test] = np.sum(np.abs(X[i_test] - self.train_X), axis=1)\n",
        "        return dists\n",
        "    #В данном случае dists - не просто сумма, а сумма по строкам записанная в строки\n",
        "\n",
        "\n",
        "    def compute_distances_no_loops(self, X):\n",
        "      num_train = self.train_X.shape[0]\n",
        "      num_test = X.shape[0]\n",
        "      dists = np.zeros((num_test, num_train), np.float32)\n",
        "\n",
        "      dists = np.sum(np.abs(X[None,:]-self.train_X[:,None]),2)\n",
        "      return dists.T\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "    def predict_labels_binary(self, dists):\n",
        "        '''\n",
        "        Returns model predictions for binary classification case\n",
        "\n",
        "        Arguments:\n",
        "        dists, np array (num_test_samples, num_train_samples) - array\n",
        "           with distances between each test and each train sample\n",
        "\n",
        "        Returns:\n",
        "        pred, np array of bool (num_test_samples) - binary predictions\n",
        "           for every test sample\n",
        "        '''\n",
        "        num_test = dists.shape[0]\n",
        "        pred = np.zeros(num_test, np.bool)\n",
        "        for i in range(num_test):\n",
        "            index = dists[i].argsort()[:self.k] #вектор индексов; i - конкретная тестовая картинка. argsort() - выдаёт k ближайших индексов\n",
        "            pred[i] = bool(np.median(self.train_y[index]))\n",
        "            pass\n",
        "        return pred\n",
        "\n",
        "    def predict_labels_multiclass(self, dists):\n",
        "        '''\n",
        "        Returns model predictions for multi-class classification case\n",
        "\n",
        "        Arguments:\n",
        "        dists, np array (num_test_samples, num_train_samples) - array\n",
        "           with distances between each test and each train sample\n",
        "\n",
        "        Returns:\n",
        "        pred, np array of int (num_test_samples) - predicted class index\n",
        "           for every test sample\n",
        "        '''\n",
        "        num_test = dists.shape[0]\n",
        "        num_test = dists.shape[0]\n",
        "        pred = np.zeros(num_test, np.int)\n",
        "        for i in range(num_test):\n",
        "            # TODO: Implement choosing best class based on k\n",
        "            # nearest training samples\n",
        "            closest_y = self.train_y[np.argsort(dists[i, :])[:self.k]] #получаем индексы наименьших k-дистанций\n",
        "            # sort by value then get indexes by slicing till k (first k in each row)\n",
        "            #print((closest_y))\n",
        "            u, indices = np.unique(closest_y, return_inverse=True)\n",
        "            #print('U',u, indices)\n",
        "            #print(u[np.argmax(np.bincount(indices))])\n",
        "            pred[i] = u[np.argmax(np.bincount(indices))]\n",
        "        return pred\n",
        "\n"
      ],
      "metadata": {
        "id": "f5jKQG0Q8BRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_classification_metrics(prediction, ground_truth):\n",
        "    '''\n",
        "    Computes metrics for binary classification\n",
        "\n",
        "    Arguments:\n",
        "    prediction, np array of bool (num_samples) - model predictions\n",
        "    ground_truth, np array of bool (num_samples) - true labels\n",
        "\n",
        "    Returns:\n",
        "    precision, recall, f1, accuracy - classification metrics\n",
        "    '''\n",
        "    tp = np.sum(np.logical_and(prediction, ground_truth))\n",
        "    fp = np.sum(np.greater(prediction, ground_truth))\n",
        "    fn = np.sum(np.less(prediction, ground_truth))\n",
        "    precision = tp/(tp + fp)\n",
        "    recall = tp/(tp+fn)\n",
        "\n",
        "    accuracy = np.sum(prediction==ground_truth)/prediction.size\n",
        "    f1 = precision*recall/(precision+recall)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "\n",
        "def multiclass_accuracy(prediction, ground_truth):\n",
        "    '''\n",
        "    Computes metrics for multiclass classification\n",
        "\n",
        "    Arguments:\n",
        "    prediction, np array of int (num_samples) - model predictions\n",
        "    ground_truth, np array of int (num_samples) - true labels\n",
        "\n",
        "    Returns:\n",
        "    accuracy - ratio of accurate predictions to total samples\n",
        "    '''\n",
        "    # TODO: Implement computing accuracy\n",
        "\n",
        "    return accuracy_score(ground_truth, prediction)"
      ],
      "metadata": {
        "id": "pylAdRoJCpxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 5\n",
        "plot_index = 1\n",
        "\n",
        "for exaample_idx in range(sample):\n",
        "  for class_idx in range(10):\n",
        "    plt.subplot(5,10, plot_index)\n",
        "    image = train_x[train_y == class_idx][exaample_idx]\n",
        "    plt.imshow(image.astype(np.uint8))\n",
        "    plt.axis('off')\n",
        "    plot_index +=1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bu8veRSohWBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнём с бинарной классификации\n"
      ],
      "metadata": {
        "id": "7EzP3D3z2ZwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_train_mask = (train_y == 0) | (train_y == 9)\n",
        "binary_train_X = train_x[binary_train_mask] #закидываем массивы в которых лежат ячейки с фотографиями 0 и 9\n",
        "binary_train_y = train_y[binary_train_mask] == 0 #закидываем значения, которые = 0. Если 0 - True, если 9 - False\n",
        "\n",
        "binary_test_mask = (test_y == 0) | (test_y == 9)\n",
        "binary_test_X = test_x[binary_test_mask]\n",
        "binary_test_y = test_y[binary_test_mask] == 0\n",
        "\n",
        "binary_train_X = binary_train_X.reshape(binary_train_X.shape[0], -1)\n",
        "binary_test_X = binary_test_X.reshape(binary_test_X.shape[0], -1)"
      ],
      "metadata": {
        "id": "SGNBatSeg1qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_train_X.shape"
      ],
      "metadata": {
        "id": "RZS5YJAt3d_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычисляет расстояние L1 от каждой выборки X до каждой обучающей выборки.\n",
        "Использует простейшую реализацию с 2 циклами\n",
        "\n",
        "Аргументы:\n",
        "X, np_array (num_test_samples, num_features) - образцы для запуска\n",
        "\n",
        "Возвращается:\n",
        "dists, np-массив (num_test_samples, num_train_samples) - массив\n",
        "с указанием расстояний между каждым тестом и каждой последовательной выборкой"
      ],
      "metadata": {
        "id": "08aDdDUIv7BU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем только с одним циклом, потому что остальное  у меня не работает..."
      ],
      "metadata": {
        "id": "7Yd59ssBrm0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_classifier = KNN(k=1)\n",
        "knn_classifier.fit(binary_train_X, binary_train_y)"
      ],
      "metadata": {
        "id": "vJN3mv1ob6Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dists = knn_classifier.compute_distances_two_loops(binary_test_X)\n",
        "assert np.isclose(dists[0, 10], np.sum(np.abs(binary_test_X[0] - binary_train_X[10])))\n",
        "#dists - матрица всех расстояний\n",
        "\n",
        "dists2 = knn_classifier.compute_distances_one_loop(binary_test_X)\n",
        "assert np.isclose(dists2[0, 10], np.sum(np.abs(binary_test_X[0] - binary_train_X[10])))\n",
        "\n",
        "dists3 = knn_classifier.compute_distances_no_loops(binary_test_X)\n",
        "assert np.isclose(dists3[0, 10], np.sum(np.abs(binary_test_X[0] - binary_train_X[10])))"
      ],
      "metadata": {
        "id": "q77lWGBS4h1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = knn_classifier.predict(binary_test_X)\n",
        "(prediction==binary_test_y) #True - good, False - no good"
      ],
      "metadata": {
        "id": "Wo2-5tuF8LXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit knn_classifier.compute_distances_two_loops(binary_test_X)\n",
        "%timeit knn_classifier.compute_distances_one_loop(binary_test_X)\n",
        "%timeit knn_classifier.compute_distances_no_loops(binary_test_X)"
      ],
      "metadata": {
        "id": "8n4BAsuLftpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics.py"
      ],
      "metadata": {
        "id": "CSApMREoqpOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1, accuracy = binary_classification_metrics(prediction, binary_test_y)\n",
        "print(\"KNN with k = %s\" % knn_classifier.k)\n",
        "print(\"Accuracy: %4.2f, Precision: %4.2f, Recall: %4.2f, F1: %4.2f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "q62LhlrYryvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cf47a4-9d7d-47a8-bd7a-ac7da9e9bc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN with k = 1\n",
            "Accuracy: 0.55, Precision: 0.57, Recall: 0.57, F1: 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_classifier_3 = KNN(k=6) #На параметре k = 6 - модель работает лучше. Понял эмперически\n",
        "knn_classifier_3.fit(binary_train_X, binary_train_y)\n",
        "prediction = knn_classifier_3.predict(binary_test_X)\n",
        "\n",
        "precision, recall, f1, accuracy = binary_classification_metrics(prediction, binary_test_y)\n",
        "print(\"KNN with k = %s\" % knn_classifier_3.k)\n",
        "print(\"Accuracy: %4.2f, Precision: %4.2f, Recall: %4.2f, F1: %4.2f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "0IkQbHSXDN6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кросс-валидация. Первый вариант"
      ],
      "metadata": {
        "id": "PVtHRclnJBxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5\n",
        "train_folds_X = []\n",
        "train_folds_y = []\n",
        "\n",
        "train_folds_X = np.array_split(binary_train_X[:(binary_train_X.shape[0]//num_folds)*num_folds], num_folds)\n",
        "train_folds_y = np.array_split(binary_train_y[:(binary_train_X.shape[0]//num_folds)*num_folds], num_folds)\n",
        "\n",
        "knn_classifier = KNN(k=3)\n",
        "knn_classifier.k = 1\n",
        "'''\n",
        "Наш датасет не делится ровно на 5 частей. поэтому код выдаёт ошибку. Чтобы её избежать я использовал операцию целочисленного деления.\n",
        "Мол, если мы делим на 5, а элементов 24, то благодаря данному способу мы в папки закинем не 5 элемментов, а 4\n",
        "'''\n",
        "# ЗАДАЧА: разделите тренировочные данные на 5 частей и сохраните их в train_folds_X/train_folds_you\n",
        "k_choices = [1, 2, 3, 5, 8, 10, 15, 20, 25, 50]\n",
        "k_to_f1 = {}  # dict mapping k values to mean F1 scores (int -> float)\n",
        "\n",
        " # ЗАДАЧА: выполнить перекрестную проверку\n",
        " # Просмотрите каждую складку и используйте ее для тестирования, а все остальные складки - для тренировки\n",
        " # Выполните обучение и создайте показатель оценки F1 на основе набора проверочных данных\n",
        " # Усредните значение F1 по всем сгибам и запишите его в k_to_f1\n",
        "\n",
        "for k in k_choices:\n",
        "  knn_classifier.k = k\n",
        "  f1_tot = 0\n",
        "  for numfold in range(num_folds):\n",
        "    Xtrain = np.concatenate(train_folds_X[:numfold] + train_folds_X[numfold+1:])\n",
        "    Ytrain = np.concatenate(train_folds_y[:numfold] + train_folds_y[numfold+1:])\n",
        "    knn_classifier.fit(Xtrain, Ytrain)\n",
        "\n",
        "    prediction = knn_classifier.predict(train_folds_X[numfold], num_loops=1    )\n",
        "    gt = train_folds_y[numfold]\n",
        "\n",
        "    precision, recall, f1, acuuracy = binary_classification_metrics(prediction, gt)\n",
        "    f1_tot += f1\n",
        "    pass\n",
        "  k_to_f1[k] = f1_tot/num_folds\n",
        "  pass\n",
        "\n",
        "for k in sorted(k_to_f1):\n",
        "  print('k = %d, f1 = %f' % (k,k_to_f1[k]))"
      ],
      "metadata": {
        "id": "XyUngBQ_Ei00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кросс-валидация\n",
        "Попробуем найти лучшее значение параметра k для алгоритма KNN!\n",
        "\n",
        "Для этого мы воспользуемся k-fold cross-validation (https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation). Мы разделим тренировочные данные на 5 фолдов (folds), и по очереди будем использовать каждый из них в качестве проверочных данных (validation data), а остальные -- в качестве тренировочных (training data).\n",
        "\n",
        "В качестве финальной оценки эффективности k мы усредним значения F1 score на всех фолдах. После этого мы просто выберем значение k с лучшим значением метрики."
      ],
      "metadata": {
        "id": "BNB14hpksdXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кросс-валидация. Второй вариант - лучше работает\n"
      ],
      "metadata": {
        "id": "W90eudoFPSY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5\n",
        "train_folds_X = np.array(np.array_split(binary_train_X, num_folds))\n",
        "train_folds_y = np.array(np.array_split(binary_train_y, num_folds))\n",
        "\n",
        "# ЗАДАЧА: разделите тренировочные данные на 5 частей и сохраните их в train_folds_X/train_folds_you\n",
        "k_choices = [1, 2, 3, 5, 8, 10, 15, 20, 25, 50]\n",
        "k_to_f1 = {}  # dict mapping k values to mean F1 scores (int -> float)\n",
        "\n",
        " # ЗАДАЧА: выполнить перекрестную проверку\n",
        " # Просмотрите каждую складку и используйте ее для тестирования, а все остальные складки - для тренировки\n",
        " # Выполните обучение и создайте показатель оценки F1 на основе набора проверочных данных\n",
        " # Усредните значение F1 по всем сгибам и запишите его в k_to_f1\n",
        "for k in k_choices:\n",
        "    f1_arr = []\n",
        "    for i in range(num_folds):\n",
        "        knn_classifier = KNN(k=k)\n",
        "        knn_classifier.fit(np.concatenate(np.delete(train_folds_X, i, axis=0)), np.concatenate(np.delete(train_folds_y, i, axis=0)))\n",
        "        prediction = knn_classifier.predict(train_folds_X[i])\n",
        "        accuracy, precision, recall, f1 = binary_classification_metrics(prediction, train_folds_y[i])\n",
        "        f1_arr.append(f1)\n",
        "    k_to_f1[k] = np.average(f1_arr)\n",
        "\n",
        "for k in sorted(k_to_f1):\n",
        "    print('k = %d, f1 = %f' % (k, k_to_f1[k]))"
      ],
      "metadata": {
        "id": "S_1XbOjTsfE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим, как хорошо работает лучшее значение k на тестовых данных (test data)"
      ],
      "metadata": {
        "id": "mzbNnzKk2ZMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Установите наилучшее значение k на наилучшее значение, найденное путем перекрестной проверки\n",
        "\n",
        "best_k = 3\n",
        "\n",
        "best_knn_classifier = KNN(k=best_k)\n",
        "best_knn_classifier.fit(binary_train_X, binary_train_y)\n",
        "prediction = best_knn_classifier.predict(binary_test_X)\n",
        "\n",
        "precision, recall, f1, accuracy = binary_classification_metrics(prediction, binary_test_y)\n",
        "print(\"Best KNN with k = %s\" % best_k)\n",
        "print(\"Accuracy: %4.2f, Precision: %4.2f, Recall: %4.2f, F1: %4.2f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "OIEH91TY2VO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Многоклассовая классификация (multi-class classification)"
      ],
      "metadata": {
        "id": "xnAmHgCA3C0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's use all 10 classes\n",
        "train_X = train_x.reshape(train_x.shape[0], -1)\n",
        "test_X = test_x.reshape(test_x.shape[0], -1)\n",
        "\n",
        "knn_classifier = KNN(k=1)\n",
        "knn_classifier.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "86a-Clvc3Do1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАДАЧА: Реализовать predict_labels_multiclass\n",
        "predict = knn_classifier.predict(test_X)\n",
        "\n",
        "# ЗАДАЧА: Реализовать мультиклассовую точность\n",
        "accuracy = multiclass_accuracy(predict, test_y)\n",
        "print(\"Accuracy: %4.2f\" % accuracy)"
      ],
      "metadata": {
        "id": "dcfrdQs13Qsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Снова кросс-валидация. Теперь нашей основной метрикой стала точность (accuracy), и ее мы тоже будем усреднять по всем фолдам.\n",
        "\n"
      ],
      "metadata": {
        "id": "s_lv5jcV9k1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best k using cross-validation based on accuracy\n",
        "num_folds = 5\n",
        "train_folds_X = np.array(np.array_split(train_X, num_folds))\n",
        "train_folds_y = np.array(np.array_split(train_y, num_folds))\n",
        "\n",
        "#ЗАДАЧА: разделите тренировочные данные на 5 частей и сохраните их в train_folds_X/train_folds_you\n",
        "\n",
        "k_choices = [1, 2, 3, 5, 8, 10, 15, 20, 25, 50]\n",
        "k_to_accuracy = {}\n",
        "\n",
        "for k in k_choices:\n",
        "    f1_arr = []\n",
        "    for i in range(num_folds):\n",
        "        knn_classifier = KNN(k=k)\n",
        "        knn_classifier.fit(np.concatenate(np.delete(train_folds_X, i, axis=0)),np.concatenate(np.delete(train_folds_y, i, axis=0)))\n",
        "        prediction = knn_classifier.predict(train_folds_X[i])\n",
        "        accuracy, precision, recall, f1 = binary_classification_metrics(prediction, train_folds_y[i])\n",
        "        f1_arr.append(f1)\n",
        "    k_to_accuracy[k] = np.average(f1_arr)\n",
        "\n",
        "for k in sorted(k_to_accuracy):\n",
        "    print('k = %d, f1 = %f' % (k, k_to_accuracy[k]))"
      ],
      "metadata": {
        "id": "eleIvScg9bhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Финальный тест - классификация на 10 классов на тестовой выборке (test data)"
      ],
      "metadata": {
        "id": "L95LV_dIHfeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Set the best k as a best from computed\n",
        "best_k = 8\n",
        "\n",
        "best_knn_classifier = KNN(k=best_k)\n",
        "best_knn_classifier.fit(train_X, train_y)\n",
        "prediction = best_knn_classifier.predict(test_X)\n",
        "\n",
        "# Accuracy should be around 20%!\n",
        "accuracy = multiclass_accuracy(prediction, test_y)\n",
        "print(\"Accuracy: %4.2f\" % accuracy)"
      ],
      "metadata": {
        "id": "_MQJFKxJHe_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aPHO5YxX9dST3KCvMhJr2aBkl1uf9uP3",
      "authorship_tag": "ABX9TyNXY4kaA8y0Qfds+V/irvCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}